{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVvMfGFcef05"
   },
   "source": [
    "# KumoRFM `rel-bench` Evaluation\n",
    "\n",
    "This notebook provides a step-by-step guide on how to evaluate the performance of `KumoRFM` on custom tasks.\n",
    "Here, we use the `rel-bench` suite as an example, but the provided guide is applicable to other datasets and tasks as well.\n",
    "\n",
    "Let's start by installing the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3Bnxq4dQTVd",
    "outputId": "071b4445-40ef-4ab7-83e6-2a8bc88c713a"
   },
   "outputs": [],
   "source": [
    "!pip install kumoai --pre --upgrade\n",
    "!pip install relbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHgET8HcQnrK"
   },
   "outputs": [],
   "source": [
    "from kumoai.experimental import rfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vYV8Yi5k5FY"
   },
   "source": [
    "Ensure that we are authorized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "Z6uTEjxCQ17v",
    "outputId": "afa810ad-6aba-4dd0-8210-ba073d396483"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.environ.get(\"KUMO_API_KEY\"):\n",
    "    rfm.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cIIhFwsDREUS",
    "outputId": "4c9b53cb-19ea-4055-db91-d2b50b6e3a23"
   },
   "outputs": [],
   "source": [
    "rfm.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCRHVjR1lAdc"
   },
   "source": [
    "Next, we write a simple function that helps us to convert any `rel-bench` dataset into a graph applicable for downstream use in `KumoRFM`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dSNjt7ERIKG"
   },
   "outputs": [],
   "source": [
    "from relbench.datasets import get_dataset\n",
    "\n",
    "def get_relbench_graph(name: str) -> rfm.LocalGraph:\n",
    "    # A helper function to create a `rfm.LocalGraph` from a `rel-bench` dataset:\n",
    "    db = get_dataset(name, download=True).get_db(upto_test_timestamp=False)\n",
    "    df_dict = {name: table.df for name, table in db.table_dict.items()}\n",
    "    graph = rfm.LocalGraph.from_data(df_dict, infer_metadata=False)\n",
    "\n",
    "    for table_name, table in db.table_dict.items():  # Set graph metadata:\n",
    "        graph[table_name].primary_key = table.pkey_col\n",
    "        graph[table_name].time_column = table.time_col\n",
    "        for fkey, dst_table in table.fkey_col_to_pkey_table.items():\n",
    "            graph.link(table_name, fkey, dst_table)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RN80_G5olKLy"
   },
   "source": [
    "For this example, we make use of the `rel-f1` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyHIswAjRdb8"
   },
   "outputs": [],
   "source": [
    "graph = get_relbench_graph('rel-f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOjA1IFXR6sv"
   },
   "source": [
    "We can easily ensure that everything is set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "-20vw-qtR0sH",
    "outputId": "a0c2987a-c9fa-4aa3-a47c-f58a85fa9220"
   },
   "outputs": [],
   "source": [
    "graph.print_metadata()\n",
    "graph.print_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "EZju9YNhR4g5",
    "outputId": "17039acb-069e-47a8-fb15-3d8aef1656f9"
   },
   "outputs": [],
   "source": [
    "graph.visualize(show_columns=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5Ba7sJhSeTv"
   },
   "source": [
    "There exists **two ways** on how to evaluate `KumoRFM` on custom datasets and tasks:\n",
    "\n",
    "1. We inject training labels and test entities via a **custom context table**. This bypasses the predictive query language and can be set up for any task.\n",
    "1. We replicate the `rel-bench` setup via the **predictive query language**.\n",
    "\n",
    "In what follows, we show how to set things up for both cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRm6Gxq7S0_j"
   },
   "source": [
    "## Custom Context Table\n",
    "\n",
    "The idea is simple: We attach a context table to the graph which contains the training and test entities, their timestamps, and training labels. For the test entities, we **keep their labels blank** and ask `KumoRFM` to infer them.\n",
    "With this scheme, we can support any classification or regressions task by interpreting them as **missing value imputation**.\n",
    "\n",
    "For `rel-bench`, we can do this by concatenating the task-specific training tables across the different splits, but ensure that we mask out all final test labels to prevent leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYqDtPeTcs38"
   },
   "source": [
    "Let's look at an example for the `user-ignore` task on the `rel-event` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9ydfQgycoz4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from relbench.tasks import get_task\n",
    "\n",
    "task = get_task('rel-f1', 'driver-top3', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "WWk_eWiTczOe",
    "outputId": "c55773e2-ddd5-4932-b4b8-4d1d2a7ccefd"
   },
   "outputs": [],
   "source": [
    "# Concatenate training labels into a single `pd.DataFrame`:\n",
    "context_dfs = []\n",
    "for split in ['test', 'val', 'train']:\n",
    "    df = task.get_table(split, mask_input_cols=False).df\n",
    "    df = df.drop(columns='index', errors='ignore')\n",
    "    df[task.target_col] = df[task.target_col].astype('Int64')\n",
    "    if split == 'test':\n",
    "        df[task.target_col] = None  # Do not leak test labels.\n",
    "    context_dfs.append(df)\n",
    "context_df = pd.concat(context_dfs, axis=0, ignore_index=True).reset_index()\n",
    "\n",
    "# Assign this `pd.DataFrame` to a table in the graph:\n",
    "context_table = rfm.LocalTable(\n",
    "    context_df,\n",
    "    name='context',\n",
    "    primary_key='index',\n",
    "    time_column=task.time_col,\n",
    ")\n",
    "graph.add_table(context_table)\n",
    "graph.link(context_table.name, task.entity_col, task.entity_table)\n",
    "\n",
    "context_table.print_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1nwcwwtdK1y"
   },
   "source": [
    "In the above snippet, note that we add a **primary key** `index` to the context table - a unique identifier to be able to reference any row within that table.\n",
    "This is needed to be able to later predict for individual rows within that table.\n",
    "\n",
    "We are now ready to evaluate `KumoRFM` on the `driver-top3` task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "fd3df99d9c784b0381add119f3f0c64f",
      "b46ca4e2d22d4a50b1a3d6491b6d8ad6"
     ]
    },
    "id": "hQxuVkq4eX5n",
    "outputId": "06e7184b-cac4-49b4-c343-e9af482c1895"
   },
   "outputs": [],
   "source": [
    "model = rfm.KumoRFM(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBzeo6r5fhIo"
   },
   "source": [
    "Our predictive query now simply performs missing value imputation for the target column in the context table. In order to cast this into a binary classification problem, we explicitely add a condition to the target clause (*i.e.* `target_col = 1`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L31FvemAfc8-"
   },
   "outputs": [],
   "source": [
    "query = (f\"PREDICT context.{task.target_col} = 1 \"\n",
    "         f\"FOR context.index IN ({{indices}})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MRiiIEzf0W7"
   },
   "source": [
    "We are now ready to iterate over all test entities (with a batch size up to `1000`) and obtain their predictions. In order to speed things up, we only run over a subset of test entities (defined by `max_test_steps`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124,
     "referenced_widgets": [
      "d8b4ff4eeaac4052957b01680485a5e0",
      "25fe2acbb50840b99dab35f193e3b922"
     ]
    },
    "id": "la9YheJHgJrQ",
    "outputId": "99386c3d-e949-4b77-b3a5-50d12ee79a1f"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 1000\n",
    "max_test_steps = 20\n",
    "\n",
    "ys_pred = []\n",
    "test_df = task.get_table('test', mask_input_cols=False).df\n",
    "steps = list(range(0, len(test_df), batch_size))[:max_test_steps]\n",
    "for i, step in enumerate(tqdm.tqdm(steps)):\n",
    "    indices = range(step, min(step + batch_size, len(test_df)))\n",
    "    _query = query.format(indices=', '.join(str(i) for i in indices))\n",
    "    df = model.predict(\n",
    "        _query,\n",
    "        run_mode='best',  # Trades runtime in favor of better model performance.\n",
    "        anchor_time='entity',  # Use context table time as anchor time.\n",
    "        num_neighbors=[8, 8, 8],  # Need to increase by 1.\n",
    "        verbose=i == 0,  # Prevent excessive logging.\n",
    "    )\n",
    "    ys_pred.append(df['True_PROB'].to_numpy())\n",
    "\n",
    "y_pred = np.concatenate(ys_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxw0fTyGgb90"
   },
   "source": [
    "There exists a few things to look out for in the code snippet above:\n",
    "\n",
    "* `KumoRFM.predict(...)` supports different **`run_mode`** configurations (`\"fast\"`, `\"normal\"`, `\"best\"`), which determine the context size, neighbor sampling parameters, and model configurations. By default, this is set to `\"fast\"`. Here, we are interested in the best possible performance.\n",
    "* The **`anchor_time`** supports two options: **(1)** a `pd.Timestamp(...)` that denotes the absolute time for when we are making a prediction; **(2)** the string `\"entity\"`, which tells `KumoRFM` to use the timestamp of the context table row as its individual anchor timestamp. In this case, we use `anchor_time=\"entity\"` since this is needed to mimic the original `rel-bench` setup.\n",
    "* The **`num_neighbors`** argument defines the depth of subgraphs and how many neighbors to sample in each hop. If unspecified, we are sampling at most two hops (which is sufficient in most cases). Since in our case we added an additional context table to the graph, we need one hop more to recover the original 2-hop sampling approach (since we first need to go from `context` to `drivers`). As such, we increase the number of hops to 3 (`len(num_neighbors) == 3`). It is important to point out that tuning the number of neighbors can be beneficial to reach maximum performance. In some cases, reducing number of neighbors avoids oversmoothing, in other cases increasing number of neighbors enables us to look at a larger historical window. In this case, we find it sufficient to sample 8 neighbors in each hop.\n",
    "* The **`verbose`** option ensures that we do not log within intermediate steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dv1NMvxiWd3"
   },
   "source": [
    "Finally, we can compute metrics based on the given ground-truth information from the `rel-bench` test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdM_LmAvibLZ",
    "outputId": "d3f3884c-17f7-4704-b13b-74ca5be51c9d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_test = test_df[task.target_col].to_numpy().astype(int)[:len(y_pred)]\n",
    "print(f'AUROC: {roc_auc_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zyUlVGdv9y4"
   },
   "source": [
    "This setup lets us benchmark any `rel-bench` task without further modifications required. If you run this set up on other tasks, results should (mostly) look as follows:\n",
    "\n",
    "| Dataset | Task | #Neighbors | AUROC |\n",
    "| - | - | - | - |\n",
    "| `rel-f1` | `driver-top3` | 8 | 90.64 |\n",
    "| `rel-f1` | `driver-dnf` | 16 | 81.98 |\n",
    "| `rel-hm` | `user-churn` | 64 | 68.82 |\n",
    "| `rel-avito` | `user-clicks` | 128 | 63.81 |\n",
    "| `rel-avito` | `user-visits` | 128 | 63.81 |\n",
    "| `rel-event` | `user-repeat` | 64 | 76.87 |\n",
    "| `rel-event` | `user-ignore` | 16 | 85.52 |\n",
    "| `rel-stack` | `user-engagement` | 8 | 86.8 |\n",
    "| `rel-stack` | `user-badge` | 8 | 84.09 |\n",
    "| `rel-trial` | `study-outcome` | 64 | 71.54 |\n",
    "| **Average** | | | **77.39** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSdKynuGikdX"
   },
   "source": [
    "## Predictive Query Language\n",
    "\n",
    "Besides the context table approach, the real beauty of `KumoRFM` comes into play once we define a task via our expressive **Predictive Query Language (PQL)**.\n",
    "\n",
    "For example, the `driver-top3` query on the `rel-f1` dataset denotes whether a driver will qualify in the top-3 for a race within the next 30 days. In PQL, we can write this as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXbtMIdnjCbY"
   },
   "outputs": [],
   "source": [
    "query = (\"PREDICT MIN(qualifying.position, 0, 30, days)<=3 \"\n",
    "         \"FOR drivers.driverId IN ({indices})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfYhfu9yjTWA"
   },
   "source": [
    "Other tasks on other datasets can be easily written via PQL as well. For example, the `user-churn` task on `rel-hm` is defined as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssV8mFG1jFCi"
   },
   "outputs": [],
   "source": [
    "(\"PREDICT COUNT(transactions.*, 0, 7, days)=0 \"\n",
    " \"FOR customer.customer_id IN ({indices}) \"\n",
    " \"WHERE COUNT(transactions.*, -7, 0, days)>0\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tknz1CwEjeVQ"
   },
   "source": [
    "which defines churn for an active customer (at least one transaction in the last week) as having no transaction in the next week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa8Rm-OTi-Rq"
   },
   "source": [
    "Whenever defining a task via PQL, it is important to ensure that the task is correctly formulated (especially around entity filters). For this, `KumoRFM` allows us to inspect and debug generated label information for a specific `anchor_time` via the `KumoRFM.get_train_table(...)` helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "76f98144ae634b4090ec37f9f7f2aca4",
      "3406dfc4f03b449fad1730cc029fdbb2"
     ]
    },
    "id": "hH7ob6XSkFeA",
    "outputId": "0744bb4f-f0a3-4d0e-e125-f36965457a0f"
   },
   "outputs": [],
   "source": [
    "# Remove context table - we no longer need it:\n",
    "del graph['context']\n",
    "\n",
    "# Ensure that target column has correct semantic type:\n",
    "graph['qualifying']['position'].stype = 'numerical'\n",
    "\n",
    "model = rfm.KumoRFM(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "ncwUWTYCkObw",
    "outputId": "921fcf38-e45a-4973-e468-e59f23f5f24c"
   },
   "outputs": [],
   "source": [
    "train_table = model.get_train_table(\n",
    "    query.format(indices='0, 1'),  # Dummy values.\n",
    "    size=100,\n",
    "    anchor_time=pd.Timestamp('2013-03-16'),\n",
    ")\n",
    "display(train_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aG-ZiFggl3wo"
   },
   "source": [
    "Let's make sure that these labels align with the labels in the `rel-bench` training table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yonmt4Xwl_7I"
   },
   "outputs": [],
   "source": [
    "test_df = task.get_table('test', mask_input_cols=False).df\n",
    "\n",
    "train_table['TARGET'] = train_table['TARGET'].astype(int)  # Align dtypes.\n",
    "train_table = train_table.rename(columns={  # Align column names:\n",
    "    'ENTITY': task.entity_col,\n",
    "    'ANCHOR_TIMESTAMP': task.time_col,\n",
    "    'TARGET': task.target_col,\n",
    "})\n",
    "assert train_table.isin(test_df.to_dict(orient='list')).all(axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sAvt8eAmCKe"
   },
   "source": [
    "Once we confirmed that everything behaves correctly, we are ready to query.\n",
    "Since `rel-bench` datasets may contain multiple anchor timestamps, we first group entities by their anchor timestamp, and then split entities within the same anchor timestamp into chunks of size `batch_size`. This ensures that for a single `model.predict(...)` call, we use the same anchor time in order to be able to share the context among all entities to predict for:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sfydkd0FmQ0Y",
    "outputId": "c44fb57c-bda3-4068-c386-c50b68a1ad47"
   },
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "max_test_steps = 20\n",
    "\n",
    "nested_test_df = test_df.groupby(task.time_col)[[\n",
    "    task.entity_col,\n",
    "    task.target_col,\n",
    "]].agg(list)\n",
    "display(nested_test_df)\n",
    "\n",
    "test_indices = []\n",
    "for anchor_time, row in nested_test_df.iterrows():\n",
    "    for step in range(0, len(row[task.entity_col]), batch_size):\n",
    "        test_indices.append((\n",
    "            anchor_time,\n",
    "            row[task.entity_col][step:step + batch_size],\n",
    "            row[task.target_col][step:step + batch_size],\n",
    "        ))\n",
    "\n",
    "# Limit the number of test steps:\n",
    "test_indices = test_indices[:max_test_steps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVNRdnaPmbzi"
   },
   "source": [
    "Afterwards, we can predict on each batch of entities (up to `1000`) that share the same anchor timestamp. This time, we pass an absolute `anchor_time` to each `model.predict(...)` call (which corresponds to the timestamp of the test set for the entities we are making a prediction for):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124,
     "referenced_widgets": [
      "18d8a31ba1a448ea84a35d4ff8001ee4",
      "beba84362b1d476d8ca7faba8dbdf163"
     ]
    },
    "id": "kcQHYNsPmYlH",
    "outputId": "1f59cab4-bad7-4af1-91e4-6f7ecd3e521b"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "ys_test = []\n",
    "ys_pred = []\n",
    "for i, (anchor_time, indices, y_test) in enumerate(tqdm.tqdm(test_indices)):\n",
    "    _query = query.format(indices=', '.join(str(i) for i in indices))\n",
    "    df = model.predict(\n",
    "        _query,\n",
    "        run_mode='best',\n",
    "        anchor_time=anchor_time,\n",
    "        max_pq_iterations=200,  # Ensure enough context labels are found.\n",
    "        verbose=i == 0,  # Prevent excessive logging.\n",
    "    )\n",
    "    ys_pred.append(df['True_PROB'].to_numpy())\n",
    "    ys_test.append(np.array(y_test))\n",
    "\n",
    "y_pred = np.concatenate(ys_pred)\n",
    "y_test = np.concatenate(ys_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pque2zQmyVJ4"
   },
   "source": [
    "One thing to point out here is that we utilize **`max_pq_iterations`** and increase its initial value from `20` to `200`. We do this in order to find sufficient context labels in the data. Often times, no adjustments are needed to the default setting, but if your predictive query comes with restrictive entity filters (*e.g.*, in our case we are only operating on active drivers defined via the `MIN` clause), it might be beneficial to increase this value in order to ensure that sufficient valid entity/timestamp pairs are found to form context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppwsqNJRoH8-"
   },
   "source": [
    "Finally, we are ready to compute metrics on top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jfNWWwxoG_z",
    "outputId": "dbd7a690-5872-49f5-ed51-8c3a04c5b5ae"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(f'AUROC: {roc_auc_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-spSkwONy87i"
   },
   "source": [
    "Note that the AUROC reported here is a bit better than what we previously reported. This is due to the fact that the `driver-top3` comes with multiple test timestamps. In the predictive query setup, all information before the current `anchor_time` will be used to generate context (*i.e.* previous test timestamps can be used as part of the context), while in the context table approach, context of other test timestamps is explicitly prohibited."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "18d8a31ba1a448ea84a35d4ff8001ee4": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_beba84362b1d476d8ca7faba8dbdf163",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">PREDICT</span><span style=\"color: #008000; text-decoration-color: #008000\"> </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">MIN</span><span style=\"color: #008000; text-decoration-color: #008000\">(qualifying.position, 0, 30, days)&lt;=3 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">FOR</span><span style=\"color: #008000; text-decoration-color: #008000\"> drivers.driverId </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">IN</span><span style=\"color: #008000; text-decoration-color: #008000\"> (0, 16, 15, 9, 17, ...) (4.64s)</span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Identified temporal binary classification task                                                        </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Collected 2,201 in-context examples with 19.04% positive cases                                        </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Generated context of size 1.25MB                                                                      </span>\n</pre>\n",
         "text/plain": "\u001b[32m✅\u001b[0m \u001b[1;32mPREDICT\u001b[0m\u001b[32m \u001b[0m\u001b[1;32mMIN\u001b[0m\u001b[32m(qualifying.position, 0, 30, days)<=3 \u001b[0m\u001b[1;32mFOR\u001b[0m\u001b[32m drivers.driverId \u001b[0m\u001b[1;32mIN\u001b[0m\u001b[32m (0, 16, 15, 9, 17, ...) (4.64s)\u001b[0m\n   \u001b[2m↳ Identified temporal binary classification task                                                        \u001b[0m\n   \u001b[2m↳ Collected 2,201 in-context examples with 19.04% positive cases                                        \u001b[0m\n   \u001b[2m↳ Generated context of size 1.25MB                                                                      \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "25fe2acbb50840b99dab35f193e3b922": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3406dfc4f03b449fad1730cc029fdbb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76f98144ae634b4090ec37f9f7f2aca4": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_3406dfc4f03b449fad1730cc029fdbb2",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅</span> <span style=\"color: #008000; text-decoration-color: #008000\">Materializing graph (0.05s)                              </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Sanitized input data                                   </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Collected primary keys from 9 tables                   </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Identified temporal graph from 1950-05-13 to 2023-11-26</span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Created graph with 97,606 nodes and 455,432 edges      </span>\n</pre>\n",
         "text/plain": "\u001b[32m✅\u001b[0m \u001b[32mMaterializing graph (0.05s)                              \u001b[0m\n   \u001b[2m↳ Sanitized input data                                   \u001b[0m\n   \u001b[2m↳ Collected primary keys from 9 tables                   \u001b[0m\n   \u001b[2m↳ Identified temporal graph from 1950-05-13 to 2023-11-26\u001b[0m\n   \u001b[2m↳ Created graph with 97,606 nodes and 455,432 edges      \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "b46ca4e2d22d4a50b1a3d6491b6d8ad6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "beba84362b1d476d8ca7faba8dbdf163": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8b4ff4eeaac4052957b01680485a5e0": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_25fe2acbb50840b99dab35f193e3b922",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">PREDICT</span><span style=\"color: #008000; text-decoration-color: #008000\"> context.qualifying=1 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">FOR</span><span style=\"color: #008000; text-decoration-color: #008000\"> context.index </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">IN</span><span style=\"color: #008000; text-decoration-color: #008000\"> (0, 1, 2, 3, 4, ...) (1.65s)</span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Identified static binary classification task                                </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Collected 1,941 in-context examples with 18.03% positive cases              </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Generated context of size 0.67MB                                            </span>\n</pre>\n",
         "text/plain": "\u001b[32m✅\u001b[0m \u001b[1;32mPREDICT\u001b[0m\u001b[32m context.qualifying=1 \u001b[0m\u001b[1;32mFOR\u001b[0m\u001b[32m context.index \u001b[0m\u001b[1;32mIN\u001b[0m\u001b[32m (0, 1, 2, 3, 4, ...) (1.65s)\u001b[0m\n   \u001b[2m↳ Identified static binary classification task                                \u001b[0m\n   \u001b[2m↳ Collected 1,941 in-context examples with 18.03% positive cases              \u001b[0m\n   \u001b[2m↳ Generated context of size 0.67MB                                            \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "fd3df99d9c784b0381add119f3f0c64f": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_b46ca4e2d22d4a50b1a3d6491b6d8ad6",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅</span> <span style=\"color: #008000; text-decoration-color: #008000\">Materializing graph (0.05s)                              </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Sanitized input data                                   </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Collected primary keys from 10 tables                  </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Identified temporal graph from 1950-05-13 to 2023-11-26</span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Created graph with 100,273 nodes and 460,766 edges     </span>\n</pre>\n",
         "text/plain": "\u001b[32m✅\u001b[0m \u001b[32mMaterializing graph (0.05s)                              \u001b[0m\n   \u001b[2m↳ Sanitized input data                                   \u001b[0m\n   \u001b[2m↳ Collected primary keys from 10 tables                  \u001b[0m\n   \u001b[2m↳ Identified temporal graph from 1950-05-13 to 2023-11-26\u001b[0m\n   \u001b[2m↳ Created graph with 100,273 nodes and 460,766 edges     \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
