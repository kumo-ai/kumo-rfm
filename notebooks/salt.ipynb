{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSWAlkHYOzGp"
   },
   "source": [
    "# KumoRFM SALT Evaluation\n",
    "\n",
    "This notebook provides a step-by-step guide on how to evaluate the performance of `KumoRFM` on the [SALT](https://github.com/SAP-samples/salt) dataset.\n",
    "\n",
    "SALT is designed to reflect real-world customer interactions within an Enterprise Resource Planning (ERP) system, where several fields are commonly missing from sales orders and must be predicted.\n",
    "It comprises four (anonymized) core tables—sales documents, sales document items, customers, and addresses—amounting to approximately 5 million records in total.\n",
    "The dataset defines eight missing fields as target variables for multi-class classification tasks.\n",
    "These tasks are characterized by significant class imbalances, a wide range of class counts (up to 589), and challenges such as label diversity, noise, and distributional drift.\n",
    "\n",
    "Let's start by installing the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyBJUqC9OGj3",
    "outputId": "97992a7f-9b14-40a5-f7fb-95c9f0b887b5"
   },
   "outputs": [],
   "source": [
    "!pip install kumoai --pre --upgrade\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9VccycvOPwI"
   },
   "outputs": [],
   "source": [
    "from kumoai.experimental import rfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lgENQIjOPDp"
   },
   "source": [
    "Ensure that we are authorized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "nZGRsyBSPTYQ",
    "outputId": "e43495a6-0f13-4a80-a4c0-f9418254899e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.environ.get(\"KUMO_API_KEY\"):\n",
    "    rfm.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cw_ZmxEjPVeq",
    "outputId": "6571db7b-91b3-4e60-daad-e3997e5a1d01"
   },
   "outputs": [],
   "source": [
    "rfm.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soAr8ok_PWvT"
   },
   "source": [
    "## Data Loading and Data Cleaning\n",
    "\n",
    "The SALT dataset is available via the [Hugging Face dataset platform](https://huggingface.co/datasets/sap-ai-research/SALT).\n",
    "You will need a Hugging Face API key to access it, which can be obtained as described [here](https://huggingface.co/docs/hub/en/security-tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "heIu0EAIQBe-",
    "outputId": "fdaf9c6d-854e-4165-fde4-c9184f706287"
   },
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "\n",
    "HUGGINGFACE_TOKEN=\"...\"  # TODO Fill\n",
    "huggingface_hub.login(HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHMp2S6eP8hu"
   },
   "source": [
    "We are now ready to load the dataset into memory. The SALT dataset is divided into an artificial training and test dataset, in which customers and addresses are shared among the two sets, while salesdocuments and salesdocument items hold distinct information (splitted by time). In order to fit this dataset into `KumoRFM`, we need to reconstruct it into its original raw dataset. We do this by simply concatenating train and test records into a single table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJWzY1_7P_Pr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "name = 'sap-ai-research/SALT'\n",
    "\n",
    "sales = pd.concat([\n",
    "    load_dataset(name, 'salesdocuments', split='train').to_pandas(),\n",
    "    load_dataset(name, 'salesdocuments', split='test').to_pandas(),\n",
    "], axis=0, ignore_index=True)\n",
    "items = pd.concat([\n",
    "    load_dataset(name, 'salesdocument_items', split='train').to_pandas(),\n",
    "    load_dataset(name, 'salesdocument_items', split='test').to_pandas(),\n",
    "], axis=0, ignore_index=True)\n",
    "customers = load_dataset(name, 'customers', split='train').to_pandas()\n",
    "addresses = load_dataset(name, 'addresses', split='train').to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBtC5QVUQlFB"
   },
   "source": [
    "Let's look at a subset of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "5gclzYPHQrmo",
    "outputId": "1b9d5e35-fb2b-4457-b722-8d427aca3403"
   },
   "outputs": [],
   "source": [
    "display(sales.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "8ALXobn3QpCj",
    "outputId": "3fedc5d3-1ed0-4bdd-e99e-060eaf5bf49e"
   },
   "outputs": [],
   "source": [
    "display(items.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4TRi2bQRSr7"
   },
   "source": [
    "We need to make a few adjustments and sanitize the data:\n",
    "\n",
    "1. We merge the `CREATIONTIME` and `CREATIONDATE` column into a single `CREATIONDATETIME` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1fvG44YRprO"
   },
   "outputs": [],
   "source": [
    "date = sales['CREATIONDATE'].astype(str)\n",
    "time = sales['CREATIONTIME'].astype(str)\n",
    "sales['CREATIONDATETIME'] = pd.to_datetime(date + ' ' + time)\n",
    "del sales['CREATIONDATE']\n",
    "del sales['CREATIONTIME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SV_poSBtRsKs"
   },
   "source": [
    "2. We add this `CREATIONDATETIME` column to the salesdocument items table as well. This is necessary to ensure the tasks of SALT on the salesdocument items table are assigned a unique timestamp to avoid temporal data leakage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQVpn45WSOsV"
   },
   "outputs": [],
   "source": [
    "items = pd.merge(\n",
    "    left=items,\n",
    "    right=sales[['SALESDOCUMENT', 'CREATIONDATETIME']],\n",
    "    how='left',\n",
    "    left_on='SALESDOCUMENT',\n",
    "    right_on='SALESDOCUMENT',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s78i2bVXSS_T"
   },
   "source": [
    "3. We remove auto-generated columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bz_poLG_SWPW"
   },
   "outputs": [],
   "source": [
    "# Remove auto-generated columns:\n",
    "del sales['__index_level_0__']\n",
    "del items['__index_level_0__']\n",
    "del customers['__index_level_0__']\n",
    "del addresses['__index_level_0__']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LY-A1IRtSY4t"
   },
   "source": [
    "4. We add a primary key to the salesdocument items table in order to ensure that we can reference its training and test records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VsPVnFUlSf_p"
   },
   "outputs": [],
   "source": [
    "items['ID'] = range(len(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVgeJtTqShZb"
   },
   "source": [
    "5. There exists an `INCOTERMSCLASSIFICATION` column in both the salesdocuments and salesdocument items table, which are both used as a target downstream. Let's rename these columns to make the two tasks easily distinguishable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4woNIFxyS0XJ"
   },
   "outputs": [],
   "source": [
    "sales = sales.rename(\n",
    "    columns={'INCOTERMSCLASSIFICATION': 'HEADERINCOTERMSCLASSIFICATION'})\n",
    "items = items.rename(\n",
    "    columns={'INCOTERMSCLASSIFICATION': 'ITEMINCOTERMSCLASSIFICATION'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfZRm1T2TFaC"
   },
   "source": [
    "According to the SALT evaluation protocol, none of the eight target columns should be used as input feature. As such, for a given task, we make sure to exclude all remaining ones.\n",
    "\n",
    "Note that you can simply change to a different task here by adjusting the `task` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOeDkHqslg6p"
   },
   "outputs": [],
   "source": [
    "sale_tasks = [\n",
    "    'SALESOFFICE',\n",
    "    'SALESGROUP',\n",
    "    'CUSTOMERPAYMENTTERMS',\n",
    "    'SHIPPINGCONDITION',\n",
    "    'HEADERINCOTERMSCLASSIFICATION',\n",
    "]\n",
    "item_tasks = [\n",
    "    'PLANT',\n",
    "    'SHIPPINGPOINT',\n",
    "    'ITEMINCOTERMSCLASSIFICATION',\n",
    "]\n",
    "\n",
    "task = 'ITEMINCOTERMSCLASSIFICATION'\n",
    "\n",
    "sales = sales.drop([t for t in sale_tasks if t != task], axis=1)\n",
    "items = items.drop([t for t in item_tasks if t != task], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHwD2-Ytn1zj"
   },
   "source": [
    "Finally, for the given task, we mask out all its test labels to prevent data leakage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iat70a9Mn-xE"
   },
   "outputs": [],
   "source": [
    "if task in sale_tasks:\n",
    "    num_test = load_dataset(name, 'salesdocuments', split='test').num_rows\n",
    "    y_test = sales[task].iloc[-num_test:].to_numpy().copy()\n",
    "    pkey_test = sales['SALESDOCUMENT'].iloc[-num_test:].to_numpy()\n",
    "    task_pos = sales.columns.get_loc(task)\n",
    "    sales.iloc[-num_test:, task_pos] = None\n",
    "elif task in item_tasks:\n",
    "    num_test = load_dataset(name, 'salesdocument_items', split='test').num_rows\n",
    "    y_test = items[task].iloc[-num_test:].to_numpy().copy()\n",
    "    pkey_test = items['ID'].iloc[-num_test:].to_numpy()\n",
    "    task_pos = items.columns.get_loc(task)\n",
    "    items.iloc[-num_test:, task_pos] = None\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported task '{task}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS6ubNMImrNb"
   },
   "source": [
    "## Graph Creation\n",
    "\n",
    "We are now ready to convert the SALT dataset into a Kumo `LocalGraph`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-zARW3zm4Qg"
   },
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    'sales': sales,\n",
    "    'items': items,\n",
    "    'customers': customers,\n",
    "    'addresses': addresses,\n",
    "}\n",
    "graph = rfm.LocalGraph.from_data(df_dict, infer_metadata=False)\n",
    "\n",
    "# \"PRODUCT\" is inferred as \"text\" column but should be marked as \"categorical\":\n",
    "graph['items']['PRODUCT'].stype = 'categorical'\n",
    "\n",
    "# Assign primary keys and time columns:\n",
    "graph['sales'].primary_key = 'SALESDOCUMENT'\n",
    "graph['sales'].time_column = 'CREATIONDATETIME'\n",
    "graph['items'].primary_key = 'ID'\n",
    "graph['items'].time_column = 'CREATIONDATETIME'\n",
    "graph['customers'].primary_key = 'CUSTOMER'\n",
    "graph['addresses'].primary_key = 'ADDRESSID'\n",
    "\n",
    "# Assign edges:\n",
    "graph.link(src_table='items', fkey='SALESDOCUMENT', dst_table='sales')\n",
    "graph.link(src_table='items', fkey='SOLDTOPARTY', dst_table='customers')\n",
    "graph.link(src_table='items', fkey='SHIPTOPARTY', dst_table='customers')\n",
    "graph.link(src_table='items', fkey='PAYERPARTY', dst_table='customers')\n",
    "graph.link(src_table='items', fkey='BILLTOPARTY', dst_table='customers')\n",
    "graph.link(src_table='customers', fkey='ADDRESSID', dst_table='addresses');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n10AF4jgm1lw"
   },
   "source": [
    "Let's ensure that everything is set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "DE5N0CRonKef",
    "outputId": "a4b0f32e-73d5-4060-cda2-a156080b6bbc"
   },
   "outputs": [],
   "source": [
    "graph.print_metadata()\n",
    "graph.print_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "1B4slo5WnXIi",
    "outputId": "f95e399c-33af-4334-b15c-c3249054a57c"
   },
   "outputs": [],
   "source": [
    "graph.visualize(show_columns=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YewbngOHnh-w"
   },
   "source": [
    "## Model Execution\n",
    "\n",
    "Once the `LocalGraph` is set up, we are ready making predictions and evaluate `KumoRFM` performance.\n",
    "\n",
    "Let's load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "f2627baa354749589f6aa4c22c19ead5",
      "f0fb4a7911144da8bd8d777610c72211"
     ]
    },
    "id": "kx0NPDwNnf20",
    "outputId": "e22512f5-10cc-428a-b5d5-fb62b4a95ff2"
   },
   "outputs": [],
   "source": [
    "model = rfm.KumoRFM(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0wygw5vntnk"
   },
   "source": [
    "The SALT tasks are multi-class classification tasks, in which we are asked to impute missing values. In `KumoRFM`, we can simply model this via the **Predictive Query Language** by predicting the target column on each of the tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ikEBVpBoaYf"
   },
   "outputs": [],
   "source": [
    "if task in sale_tasks:\n",
    "    query = f\"PREDICT sales.{task} FOR sales.SALESDOCUMENT IN ({{indices}})\"\n",
    "else:\n",
    "    query = f\"PREDICT items.{task} FOR items.ID IN ({{indices}})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbHGtakUotxw"
   },
   "source": [
    "We are now ready to iterate over all test entities (with a batch size up to `1000`) and obtain their predictions. In order to speed things up, we only run over a subset of test entities (defined by `max_test_steps`). For multi-class classification tasks, `KumoRFM` will return the probabilities of the top-10 most likely classes for each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "referenced_widgets": [
      "206ee0ff94464ffd99d549ae2c952ffd",
      "cbd0009ff98847f18ee62a25e0d2fe0d"
     ]
    },
    "id": "MNWyV267pCIm",
    "outputId": "2e06510f-6ff5-4b50-8918-07212e417576"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 1000\n",
    "max_test_steps = 10\n",
    "\n",
    "ys_pred = []\n",
    "steps = list(range(0, len(pkey_test), batch_size))[:max_test_steps]\n",
    "for i, step in enumerate(tqdm.tqdm(steps)):\n",
    "    indices = pkey_test[step:step + batch_size].tolist()\n",
    "\n",
    "    if task in sale_tasks:\n",
    "        _query = query.format(indices=', '.join(f\"'{i}'\" for i in indices))\n",
    "    else:\n",
    "       _query = query.format(indices=', '.join(str(i) for i in indices))\n",
    "\n",
    "    df = model.predict(\n",
    "        _query,\n",
    "        run_mode='best',  # Trades runtime in favor of better model performance.\n",
    "        anchor_time='entity',  # Use entity table time as anchor time.\n",
    "        num_hops=3,  # Ensure that we reach every table.\n",
    "        verbose=i == 0,  # Prevent excessive logging.\n",
    "    )\n",
    "\n",
    "    # Save the predicted top-10 classes sorted by probability:\n",
    "    ys_pred.append(df['CLASS'].to_numpy().reshape(len(indices), -1))\n",
    "\n",
    "y_pred = np.concatenate(ys_pred, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkxIxnXUo2YJ"
   },
   "source": [
    "Finally, we are ready to evaluate our predictions by comparing them to the ground-truth test labels. The metric of choice here is Mean Reciprocal Rank (MRR), *i.e.* the reciprocal rank of the correct prediction averaged over all test labels.\n",
    "\n",
    "Let's implement it quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfyqXFbpq6a4",
    "outputId": "63632c0f-66e0-4e61-f68e-ffc315ab2426"
   },
   "outputs": [],
   "source": [
    "match = y_test[:len(y_pred)].reshape(-1, 1) == y_pred\n",
    "rank = match.astype(float).argmax(axis=-1) + 1\n",
    "reciprocal_rank = 1.0 / rank\n",
    "reciprocal_rank[match.sum(axis=-1) == 0.0] = 0.0\n",
    "\n",
    "print(f'MRR: {reciprocal_rank.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVn5AVj0rEaI"
   },
   "source": [
    "And that's it! If you run the model over all different tasks, you will observe that `KumoRFM` is on par to the best baseline reported in the [SALT](https://arxiv.org/html/2501.03413v1) paper, although we never trained anything.\n",
    "Noteworthy, we are even underestimating the true MRR here, since for any correct prediction that is not within the top-10 most likely classes, we assign it a reciprocal rank of `0`.\n",
    "The only dataset where `KumoRFM` underperforms a bit is the `SALESGROUP` task, which is explained by the fact that it is the task with the most classes (589).\n",
    "\n",
    "We can further improve the performance by fine-tuning `KumoRFM` on SALT, but this is a story for another notebook. Happy hacking!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "206ee0ff94464ffd99d549ae2c952ffd": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_cbd0009ff98847f18ee62a25e0d2fe0d",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">PREDICT</span><span style=\"color: #008000; text-decoration-color: #008000\"> items.ITEMINCOTERMSCLASSIFICATION </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">FOR</span><span style=\"color: #008000; text-decoration-color: #008000\"> items.ID </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">IN</span><span style=\"color: #008000; text-decoration-color: #008000\"> (1916685, 1916686, 1916687, 1916688, 1916689, ...)    </span>\n   <span style=\"color: #008000; text-decoration-color: #008000\">(16.25s)                                                                                                        </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Identified static multi-class classification task                                                             </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Collected 10,000 in-context examples holding 12 classes                                                       </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Generated context of size 16.04MB                                                                             </span>\n</pre>\n",
         "text/plain": "\u001b[32m✅\u001b[0m \u001b[1;32mPREDICT\u001b[0m\u001b[32m items.ITEMINCOTERMSCLASSIFICATION \u001b[0m\u001b[1;32mFOR\u001b[0m\u001b[32m items.ID \u001b[0m\u001b[1;32mIN\u001b[0m\u001b[32m (1916685, 1916686, 1916687, 1916688, 1916689, ...)    \u001b[0m\n   \u001b[32m(16.25s)                                                                                                        \u001b[0m\n   \u001b[2m↳ Identified static multi-class classification task                                                             \u001b[0m\n   \u001b[2m↳ Collected 10,000 in-context examples holding 12 classes                                                       \u001b[0m\n   \u001b[2m↳ Generated context of size 16.04MB                                                                             \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "cbd0009ff98847f18ee62a25e0d2fe0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0fb4a7911144da8bd8d777610c72211": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2627baa354749589f6aa4c22c19ead5": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_f0fb4a7911144da8bd8d777610c72211",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅</span> <span style=\"color: #008000; text-decoration-color: #008000\">Materializing graph (6.21s)                              </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Sanitized input data                                   </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Collected primary keys from 4 tables                   </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Identified temporal graph from 2018-01-02 to 2020-12-31</span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Created graph with 4,748,946 nodes and 23,474,618 edges</span>\n</pre>\n",
         "text/plain": "\u001b[32m✅\u001b[0m \u001b[32mMaterializing graph (6.21s)                              \u001b[0m\n   \u001b[2m↳ Sanitized input data                                   \u001b[0m\n   \u001b[2m↳ Collected primary keys from 4 tables                   \u001b[0m\n   \u001b[2m↳ Identified temporal graph from 2018-01-02 to 2020-12-31\u001b[0m\n   \u001b[2m↳ Created graph with 4,748,946 nodes and 23,474,618 edges\u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
